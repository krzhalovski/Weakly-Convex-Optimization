{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import functions as f\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib import rc\n",
    "rc('text', usetex=True)\n",
    "\n",
    "np.random.seed(2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robust Matrix Sensing (RMS)\n",
    "\n",
    "Low-rank matrices are ubiquitous in computer vision, machine learning,\n",
    "and data science applications. One fundamental computational task is to recover a Positive Semi-Definite low-rank matrix $X^* \\in \\mathbb{R}$ with $rank(X^*) = r \\le n$ from a small number of linear measurements arbitrarily corrupted with outliers. $$y=A(X^*)+s^*$$\n",
    "\n",
    "where $A$ is a linear measurement operator consisting of a set of sensing matrices $A_{1},...,A_{m}$ and $s^*$ is a sparse outliers vector.\n",
    "\n",
    "Let us simulate this process accordingly to generate the RMS data that will be used to test the algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_RMS(m, n, r, p_fail):\n",
    "    \"\"\"\n",
    "        Auxilary function to generate the RMS data.\n",
    "        Takes as input:\n",
    "            m:\n",
    "            n:\n",
    "            r:\n",
    "            p_fail:\n",
    "        Gives as output:\n",
    "            y:\n",
    "            A:\n",
    "            X:\n",
    "    \"\"\"\n",
    "    U = np.random.normal(size=(n, r))\n",
    "    X = U@U.transpose()\n",
    "\n",
    "    y = np.zeros(m)\n",
    "    A = []\n",
    "\n",
    "    for i in range(m):\n",
    "        A.append(np.random.normal(size=(n, n)))\n",
    "        y[i] = f.trace(X.transpose()@A[i])\n",
    "\n",
    "    outliers = np.zeros(m)\n",
    "    indices = np.random.permutation(m)\n",
    "\n",
    "    limit = int(np.floor(p_fail*m))\n",
    "    chosen = indices[:limit]\n",
    "\n",
    "    outliers[chosen] = 10*np.random.normal(size=(limit))\n",
    "    y+=outliers\n",
    "    \n",
    "    return y, A, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incremental_prox_linear(mu_0, rho, U_0, n_iter, data, verbosity=0):\n",
    "    \"\"\"\n",
    "        Implementation of the incremental prox linear algorithm\n",
    "        \n",
    "        \n",
    "        Note: Make sure data is in the correct shape (y, A, X)\n",
    "    \"\"\"\n",
    "    y, A, X = data \n",
    "    \n",
    "    U = U_0\n",
    "    U_pre = U\n",
    "    \n",
    "    dist = []\n",
    "    for j in range(n_iter):\n",
    "        # Calculate the step size\n",
    "        mu = mu_0*rho**j\n",
    "        \n",
    "        dist.append(f.norm(U@U.transpose() - X))\n",
    "        if verbosity == 1:\n",
    "            print(f'Iteration: {j}, loss: {dist[j]}')\n",
    "        for i in range(m):\n",
    "            A_ = mu*(A[i] + A[i].transpose())@U_pre\n",
    "            b = -mu*f.trace(U_pre.transpose()@A[i]@U_pre) - mu*y[i]\n",
    "            \n",
    "            scaler = (f.trace(A_.transpose()@U_pre) + b) / f.norm(A_)**2\n",
    "            \n",
    "            if scaler > 1:\n",
    "                U = U_pre - A_\n",
    "            if scaler < -1:\n",
    "                U = U_pre + A_\n",
    "            if scaler >= -1 and scaler<= 1:\n",
    "                U = U_pre - scaler*A_\n",
    "            U_pre = U\n",
    "    return dist, U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_prox_linear(mu_0, rho, U_0, n_iter, data, verbosity=0):\n",
    "    \"\"\"\n",
    "        Implementation of the incremental prox linear algorithm\n",
    "        \n",
    "        \n",
    "        Note: Make sure data is in the correct shape (y, A, X)\n",
    "    \"\"\"\n",
    "    y, A, X = data \n",
    "    \n",
    "    U = U_0\n",
    "    U_pre = U\n",
    "    \n",
    "    dist = []\n",
    "    for outer in range(n_iter):\n",
    "        # Calculate the step size\n",
    "        mu = mu_0*rho**outer\n",
    "        \n",
    "        dist.append(f.norm(U@U.transpose() - X))\n",
    "        if verbosity == 1:\n",
    "            print(f'Iteration: {outer}, loss: {dist[outer]}')\n",
    "        for inner in range(m):\n",
    "            i = np.random.randint(0, m)\n",
    "            A_ = mu*(A[i] + A[i].transpose())@U_pre\n",
    "            b = -mu*f.trace(U_pre.transpose()@A[i]@U_pre) - mu*y[i]\n",
    "            \n",
    "            #if j<20 and i==2:\n",
    "            #    print(f'Iteration: {j}, norm: {f.norm(A_)**2}')\n",
    "            scaler = (f.trace(A_.transpose()@U_pre) + b) / f.norm(A_)**2\n",
    "            \n",
    "            if scaler > 1:\n",
    "                U = U_pre - A_\n",
    "            if scaler < -1:\n",
    "                U = U_pre + A_\n",
    "            if scaler >= -1 and scaler<= 1:\n",
    "                U = U_pre - scaler*A_\n",
    "            U_pre = U\n",
    "    return dist, U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 50\n",
    "r = 5\n",
    "m = 5*n*r\n",
    "p_fail = 0.3\n",
    "\n",
    "data = generate_RMS(m, n, r, p_fail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0, loss: 158.9892947209177\n",
      "Iteration: 1, loss: 40.10969197561927\n",
      "Iteration: 2, loss: 6.590834663158248\n",
      "Iteration: 3, loss: 5.445690256526125\n",
      "Iteration: 4, loss: 5.404695887035986\n",
      "Iteration: 5, loss: 5.401019180571997\n",
      "Iteration: 6, loss: 5.400899836755358\n",
      "Iteration: 7, loss: 5.400923151326844\n",
      "Iteration: 8, loss: 5.400928679530488\n",
      "Iteration: 9, loss: 5.4009294334394475\n",
      "Iteration: 10, loss: 5.400929529633916\n",
      "Iteration: 11, loss: 5.372775333418105\n",
      "Iteration: 12, loss: 5.30880294725516\n",
      "Iteration: 13, loss: 5.077622337563425\n",
      "Iteration: 14, loss: 4.651521502769742\n",
      "Iteration: 15, loss: 4.108176413291384\n",
      "Iteration: 16, loss: 3.467597167164221\n",
      "Iteration: 17, loss: 2.900136196447874\n",
      "Iteration: 18, loss: 2.4274514834409686\n",
      "Iteration: 19, loss: 2.020568433045725\n",
      "Iteration: 20, loss: 1.666252712153187\n",
      "Iteration: 21, loss: 1.3490715715776527\n",
      "Iteration: 22, loss: 1.0685999580763161\n",
      "Iteration: 23, loss: 0.8340386923450068\n",
      "Iteration: 24, loss: 0.6434165162452385\n",
      "Iteration: 25, loss: 0.49392172271790924\n",
      "Iteration: 26, loss: 0.3768770912494615\n",
      "Iteration: 27, loss: 0.2866449005391016\n",
      "Iteration: 28, loss: 0.21790735964768768\n",
      "Iteration: 29, loss: 0.16602346666218676\n",
      "Iteration: 30, loss: 0.12611314295925005\n",
      "Iteration: 31, loss: 0.09554226179325619\n",
      "Iteration: 32, loss: 0.07223604773906585\n",
      "Iteration: 33, loss: 0.05448557363502855\n",
      "Iteration: 34, loss: 0.0410519794537825\n",
      "Iteration: 35, loss: 0.03088110923582035\n",
      "Iteration: 36, loss: 0.023222786279358292\n",
      "Iteration: 37, loss: 0.01744292822872775\n",
      "Iteration: 38, loss: 0.013089405314409774\n",
      "Iteration: 39, loss: 0.009815352071607787\n",
      "Iteration: 40, loss: 0.007355473878451149\n",
      "Iteration: 41, loss: 0.005510016544438017\n",
      "Iteration: 42, loss: 0.004127491287995394\n",
      "Iteration: 43, loss: 0.0030920378211523963\n",
      "Iteration: 44, loss: 0.002316729472915353\n",
      "Iteration: 45, loss: 0.001736162038857271\n",
      "Iteration: 46, loss: 0.001301319239444626\n",
      "Iteration: 47, loss: 0.0009755317385365628\n",
      "Iteration: 48, loss: 0.0007313888947514552\n",
      "Iteration: 49, loss: 0.0005483944908391923\n",
      "Iteration: 50, loss: 0.0004112128127872648\n",
      "Iteration: 51, loss: 0.0003083631337818345\n",
      "Iteration: 52, loss: 0.0002312465541777489\n",
      "Iteration: 53, loss: 0.0001734206491544343\n",
      "Iteration: 54, loss: 0.00013005761029265598\n",
      "Iteration: 55, loss: 9.753886249659941e-05\n",
      "Iteration: 56, loss: 7.315174976271474e-05\n",
      "Iteration: 57, loss: 5.486248903950979e-05\n",
      "Iteration: 58, loss: 4.114613547352096e-05\n",
      "Iteration: 59, loss: 3.085919686913433e-05\n",
      "Iteration: 60, loss: 2.3144173258274305e-05\n",
      "Iteration: 61, loss: 1.735800533376969e-05\n",
      "Iteration: 62, loss: 1.301843465713318e-05\n",
      "Iteration: 63, loss: 9.763787365530372e-06\n",
      "Iteration: 64, loss: 7.322818963417029e-06\n",
      "Iteration: 65, loss: 5.492102201000922e-06\n",
      "Iteration: 66, loss: 4.119069919772446e-06\n",
      "Iteration: 67, loss: 3.0892986408346175e-06\n",
      "Iteration: 68, loss: 2.3169718799112734e-06\n",
      "Iteration: 69, loss: 1.7377277221926946e-06\n",
      "Iteration: 70, loss: 1.3032951414434524e-06\n",
      "Iteration: 71, loss: 9.774709761496946e-07\n",
      "Iteration: 72, loss: 7.331029932251359e-07\n",
      "Iteration: 73, loss: 5.498271112908005e-07\n",
      "Iteration: 74, loss: 4.1237029042619524e-07\n",
      "Iteration: 75, loss: 3.0927768677045836e-07\n",
      "Iteration: 76, loss: 2.3195820228814108e-07\n",
      "Iteration: 77, loss: 1.739686244671132e-07\n",
      "Iteration: 78, loss: 1.3047644052354944e-07\n",
      "Iteration: 79, loss: 9.78573334356679e-08\n",
      "Iteration: 80, loss: 7.339302840082262e-08\n",
      "Iteration: 81, loss: 5.504475351150679e-08\n",
      "Iteration: 82, loss: 4.128358779085594e-08\n",
      "Iteration: 83, loss: 3.096267541084239e-08\n",
      "Iteration: 84, loss: 2.3222001011618868e-08\n",
      "Iteration: 85, loss: 1.741651768821242e-08\n",
      "Iteration: 86, loss: 1.3062384210249696e-08\n",
      "Iteration: 87, loss: 9.796802756942238e-09\n",
      "Iteration: 88, loss: 7.347597859886302e-09\n",
      "Iteration: 89, loss: 5.510698034981866e-09\n",
      "Iteration: 90, loss: 4.133001268851119e-09\n",
      "Iteration: 91, loss: 3.0997642340304e-09\n",
      "Iteration: 92, loss: 2.324805107489745e-09\n",
      "Iteration: 93, loss: 1.7436234616002123e-09\n",
      "Iteration: 94, loss: 1.307726689663698e-09\n",
      "Iteration: 95, loss: 9.807903072160678e-10\n",
      "Iteration: 96, loss: 7.35589833428237e-10\n",
      "Iteration: 97, loss: 5.516914411668788e-10\n",
      "Iteration: 98, loss: 4.1379510254210893e-10\n",
      "Iteration: 99, loss: 3.1032521916345137e-10\n",
      "Iteration: 100, loss: 2.3275692853492518e-10\n",
      "Iteration: 101, loss: 1.7453527847711928e-10\n",
      "Iteration: 102, loss: 1.3090614854416877e-10\n",
      "Iteration: 103, loss: 9.817480189114672e-11\n",
      "Iteration: 104, loss: 7.366436267785733e-11\n",
      "Iteration: 105, loss: 5.524604679554933e-11\n",
      "Iteration: 106, loss: 4.142661646711589e-11\n",
      "Iteration: 107, loss: 3.107273490913683e-11\n",
      "Iteration: 108, loss: 2.3278722253404333e-11\n",
      "Iteration: 109, loss: 1.7453463391122754e-11\n",
      "Iteration: 110, loss: 1.3086258702954203e-11\n",
      "Iteration: 111, loss: 9.828002107529266e-12\n",
      "Iteration: 112, loss: 7.373578507311188e-12\n",
      "Iteration: 113, loss: 5.562000080181898e-12\n",
      "Iteration: 114, loss: 4.163016604113821e-12\n",
      "Iteration: 115, loss: 3.131287701650716e-12\n",
      "Iteration: 116, loss: 2.35542047948898e-12\n",
      "Iteration: 117, loss: 1.769488075039277e-12\n",
      "Iteration: 118, loss: 1.334848334652766e-12\n",
      "Iteration: 119, loss: 1.005050314185073e-12\n",
      "Iteration: 120, loss: 7.553035160393639e-13\n",
      "Iteration: 121, loss: 5.833395666320284e-13\n",
      "Iteration: 122, loss: 4.661626335976711e-13\n",
      "Iteration: 123, loss: 3.6091023371936017e-13\n",
      "Iteration: 124, loss: 3.2492466297876164e-13\n",
      "Iteration: 125, loss: 2.8424774954341447e-13\n",
      "Iteration: 126, loss: 2.5496938411913207e-13\n",
      "Iteration: 127, loss: 2.5167474891034266e-13\n",
      "Iteration: 128, loss: 2.516744866275075e-13\n",
      "Iteration: 129, loss: 2.5346158046255674e-13\n",
      "Iteration: 130, loss: 2.5632437559796915e-13\n",
      "Iteration: 131, loss: 2.5632339677161954e-13\n",
      "Iteration: 132, loss: 2.558306837346465e-13\n",
      "Iteration: 133, loss: 2.553729189294895e-13\n",
      "Iteration: 134, loss: 2.546422516836914e-13\n",
      "Iteration: 135, loss: 2.5464493087783293e-13\n",
      "Iteration: 136, loss: 2.547599691132148e-13\n",
      "Iteration: 137, loss: 2.548873146468659e-13\n",
      "Iteration: 138, loss: 2.5485837620678675e-13\n",
      "Iteration: 139, loss: 2.548227549493395e-13\n",
      "Iteration: 140, loss: 2.547631680032645e-13\n",
      "Iteration: 141, loss: 2.5476524842077844e-13\n",
      "Iteration: 142, loss: 2.547691189197859e-13\n",
      "Iteration: 143, loss: 2.548285720720994e-13\n",
      "Iteration: 144, loss: 2.548282334847968e-13\n",
      "Iteration: 145, loss: 2.548282334847968e-13\n",
      "Iteration: 146, loss: 2.548285720720994e-13\n",
      "Iteration: 147, loss: 2.548285720720994e-13\n",
      "Iteration: 148, loss: 2.548285720720994e-13\n",
      "Iteration: 149, loss: 2.548285720720994e-13\n",
      "Iteration: 150, loss: 2.548285720720994e-13\n",
      "Iteration: 151, loss: 2.548285720720994e-13\n",
      "Iteration: 152, loss: 2.548285720720994e-13\n",
      "Iteration: 153, loss: 2.548285720720994e-13\n",
      "Iteration: 154, loss: 2.548285720720994e-13\n",
      "Iteration: 155, loss: 2.548285720720994e-13\n",
      "Iteration: 156, loss: 2.548285720720994e-13\n",
      "Iteration: 157, loss: 2.548285720720994e-13\n",
      "Iteration: 158, loss: 2.548285720720994e-13\n",
      "Iteration: 159, loss: 2.548285720720994e-13\n",
      "Iteration: 160, loss: 2.548285720720994e-13\n",
      "Iteration: 161, loss: 2.548285720720994e-13\n",
      "Iteration: 162, loss: 2.548285720720994e-13\n",
      "Iteration: 163, loss: 2.548285720720994e-13\n",
      "Iteration: 164, loss: 2.548285720720994e-13\n",
      "Iteration: 165, loss: 2.548285720720994e-13\n",
      "Iteration: 166, loss: 2.548285720720994e-13\n",
      "Iteration: 167, loss: 2.548285720720994e-13\n",
      "Iteration: 168, loss: 2.548285720720994e-13\n",
      "Iteration: 169, loss: 2.548285720720994e-13\n",
      "Iteration: 170, loss: 2.548285720720994e-13\n",
      "Iteration: 171, loss: 2.548285720720994e-13\n",
      "Iteration: 172, loss: 2.548285720720994e-13\n",
      "Iteration: 173, loss: 2.548285720720994e-13\n",
      "Iteration: 174, loss: 2.548285720720994e-13\n",
      "Iteration: 175, loss: 2.548285720720994e-13\n",
      "Iteration: 176, loss: 2.548285720720994e-13\n",
      "Iteration: 177, loss: 2.548285720720994e-13\n",
      "Iteration: 178, loss: 2.548285720720994e-13\n",
      "Iteration: 179, loss: 2.548285720720994e-13\n",
      "Iteration: 180, loss: 2.548285720720994e-13\n",
      "Iteration: 181, loss: 2.548285720720994e-13\n",
      "Iteration: 182, loss: 2.548285720720994e-13\n",
      "Iteration: 183, loss: 2.548285720720994e-13\n",
      "Iteration: 184, loss: 2.548285720720994e-13\n",
      "Iteration: 185, loss: 2.548285720720994e-13\n",
      "Iteration: 186, loss: 2.548285720720994e-13\n",
      "Iteration: 187, loss: 2.548285720720994e-13\n",
      "Iteration: 188, loss: 2.548285720720994e-13\n",
      "Iteration: 189, loss: 2.548285720720994e-13\n",
      "Iteration: 190, loss: 2.548285720720994e-13\n",
      "Iteration: 191, loss: 2.548285720720994e-13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 192, loss: 2.548285720720994e-13\n",
      "Iteration: 193, loss: 2.548285720720994e-13\n",
      "Iteration: 194, loss: 2.548285720720994e-13\n",
      "Iteration: 195, loss: 2.548285720720994e-13\n",
      "Iteration: 196, loss: 2.548285720720994e-13\n",
      "Iteration: 197, loss: 2.548285720720994e-13\n",
      "Iteration: 198, loss: 2.548285720720994e-13\n",
      "Iteration: 199, loss: 2.548285720720994e-13\n",
      "Iteration: 200, loss: 2.548285720720994e-13\n",
      "Iteration: 201, loss: 2.548285720720994e-13\n",
      "Iteration: 202, loss: 2.548285720720994e-13\n",
      "Iteration: 203, loss: 2.548285720720994e-13\n",
      "Iteration: 204, loss: 2.548285720720994e-13\n",
      "Iteration: 205, loss: 2.548285720720994e-13\n",
      "Iteration: 206, loss: 2.548285720720994e-13\n",
      "Iteration: 207, loss: 2.548285720720994e-13\n",
      "Iteration: 208, loss: 2.548285720720994e-13\n",
      "Iteration: 209, loss: 2.548285720720994e-13\n",
      "Iteration: 210, loss: 2.548285720720994e-13\n",
      "Iteration: 211, loss: 2.548285720720994e-13\n",
      "Iteration: 212, loss: 2.548285720720994e-13\n",
      "Iteration: 213, loss: 2.548285720720994e-13\n",
      "Iteration: 214, loss: 2.548285720720994e-13\n",
      "Iteration: 215, loss: 2.548285720720994e-13\n",
      "Iteration: 216, loss: 2.548285720720994e-13\n",
      "Iteration: 217, loss: 2.548285720720994e-13\n",
      "Iteration: 218, loss: 2.548285720720994e-13\n",
      "Iteration: 219, loss: 2.548285720720994e-13\n",
      "Iteration: 220, loss: 2.548285720720994e-13\n",
      "Iteration: 221, loss: 2.548285720720994e-13\n",
      "Iteration: 222, loss: 2.548285720720994e-13\n",
      "Iteration: 223, loss: 2.548285720720994e-13\n",
      "Iteration: 224, loss: 2.548285720720994e-13\n",
      "Iteration: 225, loss: 2.548285720720994e-13\n",
      "Iteration: 226, loss: 2.548285720720994e-13\n",
      "Iteration: 227, loss: 2.548285720720994e-13\n",
      "Iteration: 228, loss: 2.548285720720994e-13\n",
      "Iteration: 229, loss: 2.548285720720994e-13\n",
      "Iteration: 230, loss: 2.548285720720994e-13\n",
      "Iteration: 231, loss: 2.548285720720994e-13\n",
      "Iteration: 232, loss: 2.548285720720994e-13\n",
      "Iteration: 233, loss: 2.548285720720994e-13\n",
      "Iteration: 234, loss: 2.548285720720994e-13\n",
      "Iteration: 235, loss: 2.548285720720994e-13\n",
      "Iteration: 236, loss: 2.548285720720994e-13\n",
      "Iteration: 237, loss: 2.548285720720994e-13\n",
      "Iteration: 238, loss: 2.548285720720994e-13\n",
      "Iteration: 239, loss: 2.548285720720994e-13\n",
      "Iteration: 240, loss: 2.548285720720994e-13\n",
      "Iteration: 241, loss: 2.548285720720994e-13\n",
      "Iteration: 242, loss: 2.548285720720994e-13\n",
      "Iteration: 243, loss: 2.548285720720994e-13\n",
      "Iteration: 244, loss: 2.548285720720994e-13\n",
      "Iteration: 245, loss: 2.548285720720994e-13\n",
      "Iteration: 246, loss: 2.548285720720994e-13\n",
      "Iteration: 247, loss: 2.548285720720994e-13\n",
      "Iteration: 248, loss: 2.548285720720994e-13\n",
      "Iteration: 249, loss: 2.548285720720994e-13\n",
      "Iteration: 250, loss: 2.548285720720994e-13\n",
      "Iteration: 251, loss: 2.548285720720994e-13\n",
      "Iteration: 252, loss: 2.548285720720994e-13\n",
      "Iteration: 253, loss: 2.548285720720994e-13\n",
      "Iteration: 254, loss: 2.548285720720994e-13\n",
      "Iteration: 255, loss: 2.548285720720994e-13\n",
      "Iteration: 256, loss: 2.548285720720994e-13\n",
      "Iteration: 257, loss: 2.548285720720994e-13\n",
      "Iteration: 258, loss: 2.548285720720994e-13\n",
      "Iteration: 259, loss: 2.548285720720994e-13\n",
      "Iteration: 260, loss: 2.548285720720994e-13\n",
      "Iteration: 261, loss: 2.548285720720994e-13\n",
      "Iteration: 262, loss: 2.548285720720994e-13\n",
      "Iteration: 263, loss: 2.548285720720994e-13\n",
      "Iteration: 264, loss: 2.548285720720994e-13\n",
      "Iteration: 265, loss: 2.548285720720994e-13\n",
      "Iteration: 266, loss: 2.548285720720994e-13\n",
      "Iteration: 267, loss: 2.548285720720994e-13\n",
      "Iteration: 268, loss: 2.548285720720994e-13\n",
      "Iteration: 269, loss: 2.548285720720994e-13\n",
      "Iteration: 270, loss: 2.548285720720994e-13\n",
      "Iteration: 271, loss: 2.548285720720994e-13\n",
      "Iteration: 272, loss: 2.548285720720994e-13\n",
      "Iteration: 273, loss: 2.548285720720994e-13\n",
      "Iteration: 274, loss: 2.548285720720994e-13\n",
      "Iteration: 275, loss: 2.548285720720994e-13\n",
      "Iteration: 276, loss: 2.548285720720994e-13\n",
      "Iteration: 277, loss: 2.548285720720994e-13\n",
      "Iteration: 278, loss: 2.548285720720994e-13\n",
      "Iteration: 279, loss: 2.548285720720994e-13\n",
      "Iteration: 280, loss: 2.548285720720994e-13\n",
      "Iteration: 281, loss: 2.548285720720994e-13\n",
      "Iteration: 282, loss: 2.548285720720994e-13\n",
      "Iteration: 283, loss: 2.548285720720994e-13\n",
      "Iteration: 284, loss: 2.548285720720994e-13\n",
      "Iteration: 285, loss: 2.548285720720994e-13\n",
      "Iteration: 286, loss: 2.548285720720994e-13\n",
      "Iteration: 287, loss: 2.548285720720994e-13\n",
      "Iteration: 288, loss: 2.548285720720994e-13\n",
      "Iteration: 289, loss: 2.548285720720994e-13\n",
      "Iteration: 290, loss: 2.548285720720994e-13\n",
      "Iteration: 291, loss: 2.548285720720994e-13\n",
      "Iteration: 292, loss: 2.548285720720994e-13\n",
      "Iteration: 293, loss: 2.548285720720994e-13\n",
      "Iteration: 294, loss: 2.548285720720994e-13\n",
      "Iteration: 295, loss: 2.548285720720994e-13\n",
      "Iteration: 296, loss: 2.548285720720994e-13\n",
      "Iteration: 297, loss: 2.548285720720994e-13\n",
      "Iteration: 298, loss: 2.548285720720994e-13\n",
      "Iteration: 299, loss: 2.548285720720994e-13\n",
      "Iteration: 300, loss: 2.548285720720994e-13\n",
      "Iteration: 301, loss: 2.548285720720994e-13\n",
      "Iteration: 302, loss: 2.548285720720994e-13\n",
      "Iteration: 303, loss: 2.548285720720994e-13\n",
      "Iteration: 304, loss: 2.548285720720994e-13\n",
      "Iteration: 305, loss: 2.548285720720994e-13\n",
      "Iteration: 306, loss: 2.548285720720994e-13\n",
      "Iteration: 307, loss: 2.548285720720994e-13\n",
      "Iteration: 308, loss: 2.548285720720994e-13\n",
      "Iteration: 309, loss: 2.548285720720994e-13\n",
      "Iteration: 310, loss: 2.548285720720994e-13\n",
      "Iteration: 311, loss: 2.548285720720994e-13\n",
      "Iteration: 312, loss: 2.548285720720994e-13\n",
      "Iteration: 313, loss: 2.548285720720994e-13\n",
      "Iteration: 314, loss: 2.548285720720994e-13\n",
      "Iteration: 315, loss: 2.548285720720994e-13\n",
      "Iteration: 316, loss: 2.548285720720994e-13\n",
      "Iteration: 317, loss: 2.548285720720994e-13\n",
      "Iteration: 318, loss: 2.548285720720994e-13\n",
      "Iteration: 319, loss: 2.548285720720994e-13\n",
      "Iteration: 320, loss: 2.548285720720994e-13\n",
      "Iteration: 321, loss: 2.548285720720994e-13\n",
      "Iteration: 322, loss: 2.548285720720994e-13\n",
      "Iteration: 323, loss: 2.548285720720994e-13\n",
      "Iteration: 324, loss: 2.548285720720994e-13\n",
      "Iteration: 325, loss: 2.548285720720994e-13\n",
      "Iteration: 326, loss: 2.548285720720994e-13\n",
      "Iteration: 327, loss: 2.548285720720994e-13\n",
      "Iteration: 328, loss: 2.548285720720994e-13\n",
      "Iteration: 329, loss: 2.548285720720994e-13\n",
      "Iteration: 330, loss: 2.548285720720994e-13\n",
      "Iteration: 331, loss: 2.548285720720994e-13\n",
      "Iteration: 332, loss: 2.548285720720994e-13\n",
      "Iteration: 333, loss: 2.548285720720994e-13\n",
      "Iteration: 334, loss: 2.548285720720994e-13\n",
      "Iteration: 335, loss: 2.548285720720994e-13\n",
      "Iteration: 336, loss: 2.548285720720994e-13\n",
      "Iteration: 337, loss: 2.548285720720994e-13\n",
      "Iteration: 338, loss: 2.548285720720994e-13\n",
      "Iteration: 339, loss: 2.548285720720994e-13\n",
      "Iteration: 340, loss: 2.548285720720994e-13\n",
      "Iteration: 341, loss: 2.548285720720994e-13\n",
      "Iteration: 342, loss: 2.548285720720994e-13\n",
      "Iteration: 343, loss: 2.548285720720994e-13\n",
      "Iteration: 344, loss: 2.548285720720994e-13\n",
      "Iteration: 345, loss: 2.548285720720994e-13\n",
      "Iteration: 346, loss: 2.548285720720994e-13\n",
      "Iteration: 347, loss: 2.548285720720994e-13\n",
      "Iteration: 348, loss: 2.548285720720994e-13\n",
      "Iteration: 349, loss: 2.548285720720994e-13\n",
      "Iteration: 350, loss: 2.548285720720994e-13\n",
      "Iteration: 351, loss: 2.548285720720994e-13\n",
      "Iteration: 352, loss: 2.548285720720994e-13\n",
      "Iteration: 353, loss: 2.548285720720994e-13\n",
      "Iteration: 354, loss: 2.548285720720994e-13\n",
      "Iteration: 355, loss: 2.548285720720994e-13\n",
      "Iteration: 356, loss: 2.548285720720994e-13\n",
      "Iteration: 357, loss: 2.548285720720994e-13\n",
      "Iteration: 358, loss: 2.548285720720994e-13\n",
      "Iteration: 359, loss: 2.548285720720994e-13\n",
      "Iteration: 360, loss: 2.548285720720994e-13\n",
      "Iteration: 361, loss: 2.548285720720994e-13\n",
      "Iteration: 362, loss: 2.548285720720994e-13\n",
      "Iteration: 363, loss: 2.548285720720994e-13\n",
      "Iteration: 364, loss: 2.548285720720994e-13\n",
      "Iteration: 365, loss: 2.548285720720994e-13\n",
      "Iteration: 366, loss: 2.548285720720994e-13\n",
      "Iteration: 367, loss: 2.548285720720994e-13\n",
      "Iteration: 368, loss: 2.548285720720994e-13\n",
      "Iteration: 369, loss: 2.548285720720994e-13\n",
      "Iteration: 370, loss: 2.548285720720994e-13\n",
      "Iteration: 371, loss: 2.548285720720994e-13\n",
      "Iteration: 372, loss: 2.548285720720994e-13\n",
      "Iteration: 373, loss: 2.548285720720994e-13\n",
      "Iteration: 374, loss: 2.548285720720994e-13\n",
      "Iteration: 375, loss: 2.548285720720994e-13\n",
      "Iteration: 376, loss: 2.548285720720994e-13\n",
      "Iteration: 377, loss: 2.548285720720994e-13\n",
      "Iteration: 378, loss: 2.548285720720994e-13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 379, loss: 2.548285720720994e-13\n",
      "Iteration: 380, loss: 2.548285720720994e-13\n",
      "Iteration: 381, loss: 2.548285720720994e-13\n",
      "Iteration: 382, loss: 2.548285720720994e-13\n",
      "Iteration: 383, loss: 2.548285720720994e-13\n",
      "Iteration: 384, loss: 2.548285720720994e-13\n",
      "Iteration: 385, loss: 2.548285720720994e-13\n",
      "Iteration: 386, loss: 2.548285720720994e-13\n",
      "Iteration: 387, loss: 2.548285720720994e-13\n",
      "Iteration: 388, loss: 2.548285720720994e-13\n",
      "Iteration: 389, loss: 2.548285720720994e-13\n",
      "Iteration: 390, loss: 2.548285720720994e-13\n",
      "Iteration: 391, loss: 2.548285720720994e-13\n",
      "Iteration: 392, loss: 2.548285720720994e-13\n",
      "Iteration: 393, loss: 2.548285720720994e-13\n",
      "Iteration: 394, loss: 2.548285720720994e-13\n",
      "Iteration: 395, loss: 2.548285720720994e-13\n",
      "Iteration: 396, loss: 2.548285720720994e-13\n",
      "Iteration: 397, loss: 2.548285720720994e-13\n",
      "Iteration: 398, loss: 2.548285720720994e-13\n",
      "Iteration: 399, loss: 2.548285720720994e-13\n",
      "Iteration: 400, loss: 2.548285720720994e-13\n",
      "Iteration: 401, loss: 2.548285720720994e-13\n",
      "Iteration: 402, loss: 2.548285720720994e-13\n",
      "Iteration: 403, loss: 2.548285720720994e-13\n",
      "Iteration: 404, loss: 2.548285720720994e-13\n",
      "Iteration: 405, loss: 2.548285720720994e-13\n",
      "Iteration: 406, loss: 2.548285720720994e-13\n",
      "Iteration: 407, loss: 2.548285720720994e-13\n",
      "Iteration: 408, loss: 2.548285720720994e-13\n",
      "Iteration: 409, loss: 2.548285720720994e-13\n",
      "Iteration: 410, loss: 2.548285720720994e-13\n",
      "Iteration: 411, loss: 2.548285720720994e-13\n",
      "Iteration: 412, loss: 2.548285720720994e-13\n",
      "Iteration: 413, loss: 2.548285720720994e-13\n",
      "Iteration: 414, loss: 2.548285720720994e-13\n",
      "Iteration: 415, loss: 2.548285720720994e-13\n",
      "Iteration: 416, loss: 2.548285720720994e-13\n",
      "Iteration: 417, loss: 2.548285720720994e-13\n",
      "Iteration: 418, loss: 2.548285720720994e-13\n",
      "Iteration: 419, loss: 2.548285720720994e-13\n",
      "Iteration: 420, loss: 2.548285720720994e-13\n",
      "Iteration: 421, loss: 2.548285720720994e-13\n",
      "Iteration: 422, loss: 2.548285720720994e-13\n",
      "Iteration: 423, loss: 2.548285720720994e-13\n",
      "Iteration: 424, loss: 2.548285720720994e-13\n",
      "Iteration: 425, loss: 2.548285720720994e-13\n",
      "Iteration: 426, loss: 2.548285720720994e-13\n",
      "Iteration: 427, loss: 2.548285720720994e-13\n",
      "Iteration: 428, loss: 2.548285720720994e-13\n",
      "Iteration: 429, loss: 2.548285720720994e-13\n",
      "Iteration: 430, loss: 2.548285720720994e-13\n",
      "Iteration: 431, loss: 2.548285720720994e-13\n",
      "Iteration: 432, loss: 2.548285720720994e-13\n",
      "Iteration: 433, loss: 2.548285720720994e-13\n",
      "Iteration: 434, loss: 2.548285720720994e-13\n",
      "Iteration: 435, loss: 2.548285720720994e-13\n",
      "Iteration: 436, loss: 2.548285720720994e-13\n",
      "Iteration: 437, loss: 2.548285720720994e-13\n",
      "Iteration: 438, loss: 2.548285720720994e-13\n",
      "Iteration: 439, loss: 2.548285720720994e-13\n",
      "Iteration: 440, loss: 2.548285720720994e-13\n",
      "Iteration: 441, loss: 2.548285720720994e-13\n",
      "Iteration: 442, loss: 2.548285720720994e-13\n",
      "Iteration: 443, loss: 2.548285720720994e-13\n",
      "Iteration: 444, loss: 2.548285720720994e-13\n",
      "Iteration: 445, loss: 2.548285720720994e-13\n",
      "Iteration: 446, loss: 2.548285720720994e-13\n",
      "Iteration: 447, loss: 2.548285720720994e-13\n",
      "Iteration: 448, loss: 2.548285720720994e-13\n",
      "Iteration: 449, loss: 2.548285720720994e-13\n",
      "Iteration: 450, loss: 2.548285720720994e-13\n",
      "Iteration: 451, loss: 2.548285720720994e-13\n",
      "Iteration: 452, loss: 2.548285720720994e-13\n",
      "Iteration: 453, loss: 2.548285720720994e-13\n",
      "Iteration: 454, loss: 2.548285720720994e-13\n",
      "Iteration: 455, loss: 2.548285720720994e-13\n",
      "Iteration: 456, loss: 2.548285720720994e-13\n",
      "Iteration: 457, loss: 2.548285720720994e-13\n",
      "Iteration: 458, loss: 2.548285720720994e-13\n",
      "Iteration: 459, loss: 2.548285720720994e-13\n",
      "Iteration: 460, loss: 2.548285720720994e-13\n",
      "Iteration: 461, loss: 2.548285720720994e-13\n",
      "Iteration: 462, loss: 2.548285720720994e-13\n",
      "Iteration: 463, loss: 2.548285720720994e-13\n",
      "Iteration: 464, loss: 2.548285720720994e-13\n",
      "Iteration: 465, loss: 2.548285720720994e-13\n",
      "Iteration: 466, loss: 2.548285720720994e-13\n",
      "Iteration: 467, loss: 2.548285720720994e-13\n",
      "Iteration: 468, loss: 2.548285720720994e-13\n",
      "Iteration: 469, loss: 2.548285720720994e-13\n",
      "Iteration: 470, loss: 2.548285720720994e-13\n",
      "Iteration: 471, loss: 2.548285720720994e-13\n",
      "Iteration: 472, loss: 2.548285720720994e-13\n",
      "Iteration: 473, loss: 2.548285720720994e-13\n",
      "Iteration: 474, loss: 2.548285720720994e-13\n",
      "Iteration: 475, loss: 2.548285720720994e-13\n",
      "Iteration: 476, loss: 2.548285720720994e-13\n",
      "Iteration: 477, loss: 2.548285720720994e-13\n",
      "Iteration: 478, loss: 2.548285720720994e-13\n",
      "Iteration: 479, loss: 2.548285720720994e-13\n",
      "Iteration: 480, loss: 2.548285720720994e-13\n",
      "Iteration: 481, loss: 2.548285720720994e-13\n",
      "Iteration: 482, loss: 2.548285720720994e-13\n",
      "Iteration: 483, loss: 2.548285720720994e-13\n",
      "Iteration: 484, loss: 2.548285720720994e-13\n",
      "Iteration: 485, loss: 2.548285720720994e-13\n",
      "Iteration: 486, loss: 2.548285720720994e-13\n",
      "Iteration: 487, loss: 2.548285720720994e-13\n",
      "Iteration: 488, loss: 2.548285720720994e-13\n",
      "Iteration: 489, loss: 2.548285720720994e-13\n",
      "Iteration: 490, loss: 2.548285720720994e-13\n",
      "Iteration: 491, loss: 2.548285720720994e-13\n",
      "Iteration: 492, loss: 2.548285720720994e-13\n",
      "Iteration: 493, loss: 2.548285720720994e-13\n",
      "Iteration: 494, loss: 2.548285720720994e-13\n",
      "Iteration: 495, loss: 2.548285720720994e-13\n",
      "Iteration: 496, loss: 2.548285720720994e-13\n",
      "Iteration: 497, loss: 2.548285720720994e-13\n",
      "Iteration: 498, loss: 2.548285720720994e-13\n",
      "Iteration: 499, loss: 2.548285720720994e-13\n"
     ]
    }
   ],
   "source": [
    "mu_0 = 30/m\n",
    "rho = 0.75\n",
    "U_0 = np.random.normal(size=(n, r))\n",
    "n_iter = 500\n",
    "\n",
    "model_IPL = incremental_prox_linear(mu_0, rho, U_0, n_iter, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0, loss: 147.2247591080557\n",
      "Iteration: 1, loss: 50.01077877972351\n",
      "Iteration: 2, loss: 11.268426023852212\n",
      "Iteration: 3, loss: 5.756367092653526\n",
      "Iteration: 4, loss: 5.709538069753717\n",
      "Iteration: 5, loss: 5.480902967298677\n",
      "Iteration: 6, loss: 5.399501149128737\n",
      "Iteration: 7, loss: 5.43064883604903\n",
      "Iteration: 8, loss: 5.983378219054987\n",
      "Iteration: 9, loss: 6.335878670807039\n",
      "Iteration: 10, loss: 6.075742475489608\n",
      "Iteration: 11, loss: 5.831837823452796\n",
      "Iteration: 12, loss: 5.930642452633824\n",
      "Iteration: 13, loss: 5.317978424642011\n",
      "Iteration: 14, loss: 4.865470048168535\n",
      "Iteration: 15, loss: 5.609362804745231\n",
      "Iteration: 16, loss: 5.563071946344958\n",
      "Iteration: 17, loss: 5.951001249778039\n",
      "Iteration: 18, loss: 5.264901714378184\n",
      "Iteration: 19, loss: 5.346179355390477\n",
      "Iteration: 20, loss: 5.6085533036902495\n",
      "Iteration: 21, loss: 5.340504722829099\n",
      "Iteration: 22, loss: 5.6402649113895915\n",
      "Iteration: 23, loss: 5.363974832096719\n",
      "Iteration: 24, loss: 5.6831876684809455\n",
      "Iteration: 25, loss: 5.4151156423503055\n",
      "Iteration: 26, loss: 6.174648030881192\n",
      "Iteration: 27, loss: 5.868446170636422\n",
      "Iteration: 28, loss: 6.26441799673768\n",
      "Iteration: 29, loss: 5.572449199857775\n",
      "Iteration: 30, loss: 5.9313872488161925\n",
      "Iteration: 31, loss: 5.988718945625235\n",
      "Iteration: 32, loss: 5.772812643526767\n",
      "Iteration: 33, loss: 5.4491364582858015\n",
      "Iteration: 34, loss: 4.758751554994469\n",
      "Iteration: 35, loss: 5.528138693513258\n",
      "Iteration: 36, loss: 5.0575635485838655\n",
      "Iteration: 37, loss: 5.437970347405389\n",
      "Iteration: 38, loss: 4.803074149528091\n",
      "Iteration: 39, loss: 4.647438415491057\n",
      "Iteration: 40, loss: 4.079686255006771\n",
      "Iteration: 41, loss: 3.917189141251744\n",
      "Iteration: 42, loss: 3.6116445906906613\n",
      "Iteration: 43, loss: 4.097372559017236\n",
      "Iteration: 44, loss: 3.573544767937124\n",
      "Iteration: 45, loss: 3.394136645661418\n",
      "Iteration: 46, loss: 3.33473068404458\n",
      "Iteration: 47, loss: 2.7882313868739543\n",
      "Iteration: 48, loss: 2.798014615745042\n",
      "Iteration: 49, loss: 2.8842705177315358\n",
      "Iteration: 50, loss: 2.4418515660117537\n",
      "Iteration: 51, loss: 2.6736561060503594\n",
      "Iteration: 52, loss: 2.213296167051716\n",
      "Iteration: 53, loss: 2.0153599953953316\n",
      "Iteration: 54, loss: 1.9529757303054236\n",
      "Iteration: 55, loss: 1.7542663178029607\n",
      "Iteration: 56, loss: 1.719788306172886\n",
      "Iteration: 57, loss: 1.510173451699142\n",
      "Iteration: 58, loss: 1.418620654898368\n",
      "Iteration: 59, loss: 1.147448239615518\n",
      "Iteration: 60, loss: 1.1905459210955167\n",
      "Iteration: 61, loss: 0.9541551936775479\n",
      "Iteration: 62, loss: 0.9973612893179337\n",
      "Iteration: 63, loss: 0.8757249973703667\n",
      "Iteration: 64, loss: 0.8895028486290139\n",
      "Iteration: 65, loss: 0.8129367206779575\n",
      "Iteration: 66, loss: 0.7701452428477848\n",
      "Iteration: 67, loss: 0.6924066806472563\n",
      "Iteration: 68, loss: 0.5286315519843549\n",
      "Iteration: 69, loss: 0.5421267819381027\n",
      "Iteration: 70, loss: 0.5526044953076844\n",
      "Iteration: 71, loss: 0.5058053107208862\n",
      "Iteration: 72, loss: 0.4310764955407343\n",
      "Iteration: 73, loss: 0.3916321210999255\n",
      "Iteration: 74, loss: 0.3401509994298342\n",
      "Iteration: 75, loss: 0.33319641646783205\n",
      "Iteration: 76, loss: 0.301197523435409\n",
      "Iteration: 77, loss: 0.28340756711459814\n",
      "Iteration: 78, loss: 0.27333589705163885\n",
      "Iteration: 79, loss: 0.239434996736323\n",
      "Iteration: 80, loss: 0.21594230163709732\n",
      "Iteration: 81, loss: 0.2001022047639538\n",
      "Iteration: 82, loss: 0.17341988479973627\n",
      "Iteration: 83, loss: 0.16476554654717546\n",
      "Iteration: 84, loss: 0.15884840077758375\n",
      "Iteration: 85, loss: 0.13954097310842825\n",
      "Iteration: 86, loss: 0.12940889904981484\n",
      "Iteration: 87, loss: 0.11123721253937333\n",
      "Iteration: 88, loss: 0.09124246850955044\n",
      "Iteration: 89, loss: 0.08567599050934564\n",
      "Iteration: 90, loss: 0.07560459536965405\n",
      "Iteration: 91, loss: 0.06225555669306239\n",
      "Iteration: 92, loss: 0.05547288574916881\n",
      "Iteration: 93, loss: 0.053399651805676775\n",
      "Iteration: 94, loss: 0.04498047451979849\n",
      "Iteration: 95, loss: 0.03971804000849136\n",
      "Iteration: 96, loss: 0.037447540471789276\n",
      "Iteration: 97, loss: 0.035840912160874754\n",
      "Iteration: 98, loss: 0.03390251381600532\n",
      "Iteration: 99, loss: 0.026752670380289438\n",
      "Iteration: 100, loss: 0.02584128882378548\n",
      "Iteration: 101, loss: 0.019386152007382387\n",
      "Iteration: 102, loss: 0.02050339390851384\n",
      "Iteration: 103, loss: 0.016134340960979723\n",
      "Iteration: 104, loss: 0.017300990073327114\n",
      "Iteration: 105, loss: 0.014417164304797487\n",
      "Iteration: 106, loss: 0.01322847527855433\n",
      "Iteration: 107, loss: 0.01179227443873358\n",
      "Iteration: 108, loss: 0.01069718267962301\n",
      "Iteration: 109, loss: 0.010648543501512708\n",
      "Iteration: 110, loss: 0.010475752384564515\n",
      "Iteration: 111, loss: 0.00997880961108486\n",
      "Iteration: 112, loss: 0.008867071371427062\n",
      "Iteration: 113, loss: 0.0076652704898665415\n",
      "Iteration: 114, loss: 0.006971453033614276\n",
      "Iteration: 115, loss: 0.006086408897516445\n",
      "Iteration: 116, loss: 0.005566160599790199\n",
      "Iteration: 117, loss: 0.0047328701076634104\n",
      "Iteration: 118, loss: 0.004023209974555106\n",
      "Iteration: 119, loss: 0.0033089016281944343\n",
      "Iteration: 120, loss: 0.0031233453536624006\n",
      "Iteration: 121, loss: 0.0031368712426025716\n",
      "Iteration: 122, loss: 0.002834473477403874\n",
      "Iteration: 123, loss: 0.0023550774637173385\n",
      "Iteration: 124, loss: 0.0021389767395073906\n",
      "Iteration: 125, loss: 0.0017196024179657189\n",
      "Iteration: 126, loss: 0.001916822526542341\n",
      "Iteration: 127, loss: 0.0016753867814712868\n",
      "Iteration: 128, loss: 0.0015945099923672028\n",
      "Iteration: 129, loss: 0.0014156267733647595\n",
      "Iteration: 130, loss: 0.0012000147205476807\n",
      "Iteration: 131, loss: 0.0010026952042443275\n",
      "Iteration: 132, loss: 0.0009371025019071935\n",
      "Iteration: 133, loss: 0.0007697820292650467\n",
      "Iteration: 134, loss: 0.0006108616771906388\n",
      "Iteration: 135, loss: 0.0006099675876308445\n",
      "Iteration: 136, loss: 0.0005380094641069775\n",
      "Iteration: 137, loss: 0.0004959230187435635\n",
      "Iteration: 138, loss: 0.0005073357554520615\n",
      "Iteration: 139, loss: 0.0004301235723715775\n",
      "Iteration: 140, loss: 0.0003876063022637806\n",
      "Iteration: 141, loss: 0.00036192050666935074\n",
      "Iteration: 142, loss: 0.0003157274157578943\n",
      "Iteration: 143, loss: 0.00031658250879940407\n",
      "Iteration: 144, loss: 0.00025934460248843295\n",
      "Iteration: 145, loss: 0.0002253124130459519\n",
      "Iteration: 146, loss: 0.00019471377097991547\n",
      "Iteration: 147, loss: 0.00018050980560401636\n",
      "Iteration: 148, loss: 0.00014592234438351472\n",
      "Iteration: 149, loss: 0.00012875286140556595\n",
      "Iteration: 150, loss: 0.00011524667955051048\n",
      "Iteration: 151, loss: 0.0001092989833286505\n",
      "Iteration: 152, loss: 9.738078234369695e-05\n",
      "Iteration: 153, loss: 8.762837758314221e-05\n",
      "Iteration: 154, loss: 9.283613084410453e-05\n",
      "Iteration: 155, loss: 8.498635571061803e-05\n",
      "Iteration: 156, loss: 7.894617485977108e-05\n",
      "Iteration: 157, loss: 7.373998662538318e-05\n",
      "Iteration: 158, loss: 6.651796721875646e-05\n",
      "Iteration: 159, loss: 6.031558192497709e-05\n",
      "Iteration: 160, loss: 5.39088048357364e-05\n",
      "Iteration: 161, loss: 4.6621198804195646e-05\n",
      "Iteration: 162, loss: 4.157938026554643e-05\n",
      "Iteration: 163, loss: 3.67130814921755e-05\n",
      "Iteration: 164, loss: 3.116380324277829e-05\n",
      "Iteration: 165, loss: 2.852877804075453e-05\n",
      "Iteration: 166, loss: 2.2539764510585567e-05\n",
      "Iteration: 167, loss: 2.002634709437244e-05\n",
      "Iteration: 168, loss: 1.820964868765056e-05\n",
      "Iteration: 169, loss: 1.5939374659197832e-05\n",
      "Iteration: 170, loss: 1.4935498704871172e-05\n",
      "Iteration: 171, loss: 1.294049925533725e-05\n",
      "Iteration: 172, loss: 1.3526264369721638e-05\n",
      "Iteration: 173, loss: 1.4056046646436082e-05\n",
      "Iteration: 174, loss: 1.207090073066732e-05\n",
      "Iteration: 175, loss: 1.072139091992215e-05\n",
      "Iteration: 176, loss: 8.979386568561505e-06\n",
      "Iteration: 177, loss: 7.52562882132076e-06\n",
      "Iteration: 178, loss: 6.811799640088487e-06\n",
      "Iteration: 179, loss: 6.411267076911795e-06\n",
      "Iteration: 180, loss: 5.453510076737402e-06\n",
      "Iteration: 181, loss: 4.802760590551258e-06\n",
      "Iteration: 182, loss: 4.251490513575912e-06\n",
      "Iteration: 183, loss: 3.830113359249954e-06\n",
      "Iteration: 184, loss: 3.4534971305881543e-06\n",
      "Iteration: 185, loss: 3.1122981668754418e-06\n",
      "Iteration: 186, loss: 2.9392112398752484e-06\n",
      "Iteration: 187, loss: 2.707723311633676e-06\n",
      "Iteration: 188, loss: 2.444900561343475e-06\n",
      "Iteration: 189, loss: 2.4050316601992127e-06\n",
      "Iteration: 190, loss: 2.063387450053267e-06\n",
      "Iteration: 191, loss: 1.9324057956606076e-06\n",
      "Iteration: 192, loss: 1.5703215959184456e-06\n",
      "Iteration: 193, loss: 1.272065259248487e-06\n",
      "Iteration: 194, loss: 1.2582670734016137e-06\n",
      "Iteration: 195, loss: 1.0164262875401356e-06\n",
      "Iteration: 196, loss: 8.950247689721451e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 197, loss: 8.537795658952428e-07\n",
      "Iteration: 198, loss: 7.671551678974407e-07\n",
      "Iteration: 199, loss: 7.103789727353043e-07\n",
      "Iteration: 200, loss: 5.80037710905768e-07\n",
      "Iteration: 201, loss: 5.718559920635635e-07\n",
      "Iteration: 202, loss: 5.161035407117469e-07\n",
      "Iteration: 203, loss: 4.7435373844644805e-07\n",
      "Iteration: 204, loss: 4.810532790565163e-07\n",
      "Iteration: 205, loss: 4.311521075590393e-07\n",
      "Iteration: 206, loss: 3.835142147523274e-07\n",
      "Iteration: 207, loss: 3.101632904880619e-07\n",
      "Iteration: 208, loss: 3.1476306007587115e-07\n",
      "Iteration: 209, loss: 2.9772158263181534e-07\n",
      "Iteration: 210, loss: 2.7460771005082685e-07\n",
      "Iteration: 211, loss: 2.5692782323805284e-07\n",
      "Iteration: 212, loss: 2.117296098870071e-07\n",
      "Iteration: 213, loss: 1.7037255718713893e-07\n",
      "Iteration: 214, loss: 1.584340245651172e-07\n",
      "Iteration: 215, loss: 1.4522436276446952e-07\n",
      "Iteration: 216, loss: 1.3308233855937215e-07\n",
      "Iteration: 217, loss: 1.3376239842519994e-07\n",
      "Iteration: 218, loss: 1.1270168572845173e-07\n",
      "Iteration: 219, loss: 1.1391786159282014e-07\n",
      "Iteration: 220, loss: 1.0055588319005685e-07\n",
      "Iteration: 221, loss: 9.580822690866233e-08\n",
      "Iteration: 222, loss: 8.060825390906952e-08\n",
      "Iteration: 223, loss: 7.257313960062688e-08\n",
      "Iteration: 224, loss: 6.613129665249e-08\n",
      "Iteration: 225, loss: 5.67892719235425e-08\n",
      "Iteration: 226, loss: 5.2330445520558126e-08\n",
      "Iteration: 227, loss: 4.74886398644462e-08\n",
      "Iteration: 228, loss: 4.1868814519819245e-08\n",
      "Iteration: 229, loss: 3.9727059330159935e-08\n",
      "Iteration: 230, loss: 3.7613882843833383e-08\n",
      "Iteration: 231, loss: 3.3660519215057286e-08\n",
      "Iteration: 232, loss: 2.9997345743827854e-08\n",
      "Iteration: 233, loss: 2.3456406736390343e-08\n",
      "Iteration: 234, loss: 1.9810821288004785e-08\n",
      "Iteration: 235, loss: 1.8716237052408744e-08\n",
      "Iteration: 236, loss: 1.5864406917150536e-08\n",
      "Iteration: 237, loss: 1.3822532661023462e-08\n",
      "Iteration: 238, loss: 1.2324596041675996e-08\n",
      "Iteration: 239, loss: 1.1059565663713962e-08\n",
      "Iteration: 240, loss: 1.0104365857664583e-08\n",
      "Iteration: 241, loss: 8.129504119145823e-09\n",
      "Iteration: 242, loss: 6.9934624788527806e-09\n",
      "Iteration: 243, loss: 6.450826973266321e-09\n",
      "Iteration: 244, loss: 6.340822996517417e-09\n",
      "Iteration: 245, loss: 5.383151604978003e-09\n",
      "Iteration: 246, loss: 5.554072998791306e-09\n",
      "Iteration: 247, loss: 5.166323399460213e-09\n",
      "Iteration: 248, loss: 4.688495519308961e-09\n",
      "Iteration: 249, loss: 4.436164467003165e-09\n",
      "Iteration: 250, loss: 3.91071451629231e-09\n",
      "Iteration: 251, loss: 3.4135653479910835e-09\n",
      "Iteration: 252, loss: 2.7365833345068574e-09\n",
      "Iteration: 253, loss: 2.386453501975077e-09\n",
      "Iteration: 254, loss: 2.1342947319859228e-09\n",
      "Iteration: 255, loss: 2.04611745700026e-09\n",
      "Iteration: 256, loss: 1.9784224555398025e-09\n",
      "Iteration: 257, loss: 1.6800154977227029e-09\n",
      "Iteration: 258, loss: 1.5138219133520254e-09\n",
      "Iteration: 259, loss: 1.31267864005695e-09\n",
      "Iteration: 260, loss: 1.2395808788368614e-09\n",
      "Iteration: 261, loss: 1.184592370446713e-09\n",
      "Iteration: 262, loss: 1.0466586764522016e-09\n",
      "Iteration: 263, loss: 1.0298371526882584e-09\n",
      "Iteration: 264, loss: 9.425974686893291e-10\n",
      "Iteration: 265, loss: 8.44358730190782e-10\n",
      "Iteration: 266, loss: 7.074584792153086e-10\n",
      "Iteration: 267, loss: 6.319622234657997e-10\n",
      "Iteration: 268, loss: 5.701519936063629e-10\n",
      "Iteration: 269, loss: 4.804916252400001e-10\n",
      "Iteration: 270, loss: 4.372393166986426e-10\n",
      "Iteration: 271, loss: 3.459719011239128e-10\n",
      "Iteration: 272, loss: 3.1909773588066296e-10\n",
      "Iteration: 273, loss: 3.1323973571837033e-10\n",
      "Iteration: 274, loss: 2.8271798952269504e-10\n",
      "Iteration: 275, loss: 2.688262626409471e-10\n",
      "Iteration: 276, loss: 2.5170180985881724e-10\n",
      "Iteration: 277, loss: 1.99482896058368e-10\n",
      "Iteration: 278, loss: 1.8924314988419335e-10\n",
      "Iteration: 279, loss: 1.6992385448856255e-10\n",
      "Iteration: 280, loss: 1.3725973203986716e-10\n",
      "Iteration: 281, loss: 1.288612359651818e-10\n",
      "Iteration: 282, loss: 1.2358760909143183e-10\n",
      "Iteration: 283, loss: 1.0520962169617972e-10\n",
      "Iteration: 284, loss: 1.018208772873316e-10\n",
      "Iteration: 285, loss: 9.361425772773135e-11\n",
      "Iteration: 286, loss: 8.466098597095699e-11\n",
      "Iteration: 287, loss: 7.698626598159974e-11\n",
      "Iteration: 288, loss: 7.108934149383529e-11\n",
      "Iteration: 289, loss: 6.560620797748206e-11\n",
      "Iteration: 290, loss: 5.918507278073317e-11\n",
      "Iteration: 291, loss: 5.693514050507186e-11\n",
      "Iteration: 292, loss: 4.965808331301913e-11\n",
      "Iteration: 293, loss: 4.3516729921490196e-11\n",
      "Iteration: 294, loss: 3.9566461317441266e-11\n",
      "Iteration: 295, loss: 3.7562253751065384e-11\n",
      "Iteration: 296, loss: 3.100226988544957e-11\n",
      "Iteration: 297, loss: 2.728644287897246e-11\n",
      "Iteration: 298, loss: 2.5861554356702653e-11\n",
      "Iteration: 299, loss: 2.086794881766216e-11\n",
      "Iteration: 300, loss: 2.079941584763954e-11\n",
      "Iteration: 301, loss: 1.7492707022707738e-11\n",
      "Iteration: 302, loss: 1.6986386372581382e-11\n",
      "Iteration: 303, loss: 1.3953791157246784e-11\n",
      "Iteration: 304, loss: 1.3122725439720259e-11\n",
      "Iteration: 305, loss: 1.1618151676444365e-11\n",
      "Iteration: 306, loss: 1.0601772608573055e-11\n",
      "Iteration: 307, loss: 1.0757297761704279e-11\n",
      "Iteration: 308, loss: 9.617765724943295e-12\n",
      "Iteration: 309, loss: 8.396514908077213e-12\n",
      "Iteration: 310, loss: 6.7526216250012695e-12\n",
      "Iteration: 311, loss: 6.381768970443992e-12\n",
      "Iteration: 312, loss: 5.946221078745031e-12\n",
      "Iteration: 313, loss: 5.190596195787286e-12\n",
      "Iteration: 314, loss: 3.90644687602915e-12\n",
      "Iteration: 315, loss: 3.4462922563341484e-12\n",
      "Iteration: 316, loss: 3.225127414064804e-12\n",
      "Iteration: 317, loss: 2.5861619056781808e-12\n",
      "Iteration: 318, loss: 2.2743162958230067e-12\n",
      "Iteration: 319, loss: 2.216078331735669e-12\n",
      "Iteration: 320, loss: 1.8919348943270172e-12\n",
      "Iteration: 321, loss: 1.859527750099075e-12\n",
      "Iteration: 322, loss: 1.5872905354256004e-12\n",
      "Iteration: 323, loss: 1.6039622378899008e-12\n",
      "Iteration: 324, loss: 1.2766231574985537e-12\n",
      "Iteration: 325, loss: 1.1602095133895339e-12\n",
      "Iteration: 326, loss: 1.0925427530627777e-12\n",
      "Iteration: 327, loss: 1.031800451574687e-12\n",
      "Iteration: 328, loss: 9.666615501662293e-13\n",
      "Iteration: 329, loss: 1.022146029851488e-12\n",
      "Iteration: 330, loss: 9.205477294872459e-13\n",
      "Iteration: 331, loss: 8.817044969498505e-13\n",
      "Iteration: 332, loss: 7.804838801074163e-13\n",
      "Iteration: 333, loss: 6.66968547254948e-13\n",
      "Iteration: 334, loss: 5.92431964081995e-13\n",
      "Iteration: 335, loss: 5.789490351675352e-13\n",
      "Iteration: 336, loss: 5.341841491173031e-13\n",
      "Iteration: 337, loss: 4.885643287819987e-13\n",
      "Iteration: 338, loss: 4.664237386915229e-13\n",
      "Iteration: 339, loss: 4.360820453017645e-13\n",
      "Iteration: 340, loss: 4.2286173606512575e-13\n",
      "Iteration: 341, loss: 4.241131016766751e-13\n",
      "Iteration: 342, loss: 4.636729509997689e-13\n",
      "Iteration: 343, loss: 4.5077137551979445e-13\n",
      "Iteration: 344, loss: 4.4198006462542886e-13\n",
      "Iteration: 345, loss: 4.480495946936278e-13\n",
      "Iteration: 346, loss: 4.616846848711047e-13\n",
      "Iteration: 347, loss: 4.725476173625294e-13\n",
      "Iteration: 348, loss: 4.769984729952457e-13\n",
      "Iteration: 349, loss: 4.733946335163228e-13\n",
      "Iteration: 350, loss: 4.82955303639838e-13\n",
      "Iteration: 351, loss: 4.834950289329694e-13\n",
      "Iteration: 352, loss: 4.855908994039981e-13\n",
      "Iteration: 353, loss: 4.905038415720902e-13\n",
      "Iteration: 354, loss: 4.883143399250824e-13\n",
      "Iteration: 355, loss: 4.900247517988616e-13\n",
      "Iteration: 356, loss: 4.919964778965381e-13\n",
      "Iteration: 357, loss: 4.944661171900413e-13\n",
      "Iteration: 358, loss: 4.958070725527013e-13\n",
      "Iteration: 359, loss: 4.984507493605723e-13\n",
      "Iteration: 360, loss: 4.995073012043853e-13\n",
      "Iteration: 361, loss: 4.987311967425255e-13\n",
      "Iteration: 362, loss: 4.975785312551693e-13\n",
      "Iteration: 363, loss: 4.968295734734668e-13\n",
      "Iteration: 364, loss: 4.970875708776904e-13\n",
      "Iteration: 365, loss: 4.977820923773674e-13\n",
      "Iteration: 366, loss: 4.971104678755757e-13\n",
      "Iteration: 367, loss: 4.972451227130911e-13\n",
      "Iteration: 368, loss: 4.969490763069045e-13\n",
      "Iteration: 369, loss: 4.968080663002487e-13\n",
      "Iteration: 370, loss: 4.969268557793004e-13\n",
      "Iteration: 371, loss: 4.966657918862396e-13\n",
      "Iteration: 372, loss: 4.965699013819323e-13\n",
      "Iteration: 373, loss: 4.96581647955809e-13\n",
      "Iteration: 374, loss: 4.965507879426552e-13\n",
      "Iteration: 375, loss: 4.966799036714549e-13\n",
      "Iteration: 376, loss: 4.966811501269672e-13\n",
      "Iteration: 377, loss: 4.96675867065173e-13\n",
      "Iteration: 378, loss: 4.967226293896757e-13\n",
      "Iteration: 379, loss: 4.967317063938829e-13\n",
      "Iteration: 380, loss: 4.967493812811916e-13\n",
      "Iteration: 381, loss: 4.967049967835666e-13\n",
      "Iteration: 382, loss: 4.967026441582281e-13\n",
      "Iteration: 383, loss: 4.967519754190196e-13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 384, loss: 4.966989735751541e-13\n",
      "Iteration: 385, loss: 4.96598144558232e-13\n",
      "Iteration: 386, loss: 4.964160463144006e-13\n",
      "Iteration: 387, loss: 4.963619018048236e-13\n",
      "Iteration: 388, loss: 4.963634041742504e-13\n",
      "Iteration: 389, loss: 4.963646628707549e-13\n",
      "Iteration: 390, loss: 4.963176753196093e-13\n",
      "Iteration: 391, loss: 4.962915297921923e-13\n",
      "Iteration: 392, loss: 4.962915297921923e-13\n",
      "Iteration: 393, loss: 4.962935166771147e-13\n",
      "Iteration: 394, loss: 4.96226715727644e-13\n",
      "Iteration: 395, loss: 4.96226715727644e-13\n",
      "Iteration: 396, loss: 4.96226715727644e-13\n",
      "Iteration: 397, loss: 4.962935166771147e-13\n",
      "Iteration: 398, loss: 4.962935166771147e-13\n",
      "Iteration: 399, loss: 4.962935166771147e-13\n",
      "Iteration: 400, loss: 4.962935166771147e-13\n",
      "Iteration: 401, loss: 4.962935166771147e-13\n",
      "Iteration: 402, loss: 4.962935166771147e-13\n",
      "Iteration: 403, loss: 4.962935166771147e-13\n",
      "Iteration: 404, loss: 4.962935166771147e-13\n",
      "Iteration: 405, loss: 4.962935166771147e-13\n",
      "Iteration: 406, loss: 4.962935166771147e-13\n",
      "Iteration: 407, loss: 4.962935166771147e-13\n",
      "Iteration: 408, loss: 4.962935166771147e-13\n",
      "Iteration: 409, loss: 4.962935166771147e-13\n",
      "Iteration: 410, loss: 4.962935166771147e-13\n",
      "Iteration: 411, loss: 4.962935166771147e-13\n",
      "Iteration: 412, loss: 4.962935166771147e-13\n",
      "Iteration: 413, loss: 4.962935166771147e-13\n",
      "Iteration: 414, loss: 4.962935166771147e-13\n",
      "Iteration: 415, loss: 4.962935166771147e-13\n",
      "Iteration: 416, loss: 4.962935166771147e-13\n",
      "Iteration: 417, loss: 4.962935166771147e-13\n",
      "Iteration: 418, loss: 4.962935166771147e-13\n",
      "Iteration: 419, loss: 4.962935166771147e-13\n",
      "Iteration: 420, loss: 4.962935166771147e-13\n",
      "Iteration: 421, loss: 4.962935166771147e-13\n",
      "Iteration: 422, loss: 4.962935166771147e-13\n",
      "Iteration: 423, loss: 4.962935166771147e-13\n",
      "Iteration: 424, loss: 4.962935166771147e-13\n",
      "Iteration: 425, loss: 4.962935166771147e-13\n",
      "Iteration: 426, loss: 4.962935166771147e-13\n",
      "Iteration: 427, loss: 4.962935166771147e-13\n",
      "Iteration: 428, loss: 4.962935166771147e-13\n",
      "Iteration: 429, loss: 4.962935166771147e-13\n",
      "Iteration: 430, loss: 4.962935166771147e-13\n",
      "Iteration: 431, loss: 4.962935166771147e-13\n",
      "Iteration: 432, loss: 4.962935166771147e-13\n",
      "Iteration: 433, loss: 4.962935166771147e-13\n",
      "Iteration: 434, loss: 4.962935166771147e-13\n",
      "Iteration: 435, loss: 4.962935166771147e-13\n",
      "Iteration: 436, loss: 4.962935166771147e-13\n",
      "Iteration: 437, loss: 4.962935166771147e-13\n",
      "Iteration: 438, loss: 4.962935166771147e-13\n",
      "Iteration: 439, loss: 4.962935166771147e-13\n",
      "Iteration: 440, loss: 4.962935166771147e-13\n",
      "Iteration: 441, loss: 4.962935166771147e-13\n",
      "Iteration: 442, loss: 4.962935166771147e-13\n",
      "Iteration: 443, loss: 4.962935166771147e-13\n",
      "Iteration: 444, loss: 4.962935166771147e-13\n",
      "Iteration: 445, loss: 4.962935166771147e-13\n",
      "Iteration: 446, loss: 4.962935166771147e-13\n",
      "Iteration: 447, loss: 4.962935166771147e-13\n",
      "Iteration: 448, loss: 4.962935166771147e-13\n",
      "Iteration: 449, loss: 4.962935166771147e-13\n",
      "Iteration: 450, loss: 4.962935166771147e-13\n",
      "Iteration: 451, loss: 4.962935166771147e-13\n",
      "Iteration: 452, loss: 4.962935166771147e-13\n",
      "Iteration: 453, loss: 4.962935166771147e-13\n",
      "Iteration: 454, loss: 4.962935166771147e-13\n",
      "Iteration: 455, loss: 4.962935166771147e-13\n",
      "Iteration: 456, loss: 4.962935166771147e-13\n",
      "Iteration: 457, loss: 4.962935166771147e-13\n",
      "Iteration: 458, loss: 4.962935166771147e-13\n",
      "Iteration: 459, loss: 4.962935166771147e-13\n",
      "Iteration: 460, loss: 4.962935166771147e-13\n",
      "Iteration: 461, loss: 4.962935166771147e-13\n",
      "Iteration: 462, loss: 4.962935166771147e-13\n",
      "Iteration: 463, loss: 4.962935166771147e-13\n",
      "Iteration: 464, loss: 4.962935166771147e-13\n",
      "Iteration: 465, loss: 4.962935166771147e-13\n",
      "Iteration: 466, loss: 4.962935166771147e-13\n",
      "Iteration: 467, loss: 4.962935166771147e-13\n",
      "Iteration: 468, loss: 4.962935166771147e-13\n",
      "Iteration: 469, loss: 4.962935166771147e-13\n",
      "Iteration: 470, loss: 4.962935166771147e-13\n",
      "Iteration: 471, loss: 4.962935166771147e-13\n",
      "Iteration: 472, loss: 4.962935166771147e-13\n",
      "Iteration: 473, loss: 4.962935166771147e-13\n",
      "Iteration: 474, loss: 4.962935166771147e-13\n",
      "Iteration: 475, loss: 4.962935166771147e-13\n",
      "Iteration: 476, loss: 4.962935166771147e-13\n",
      "Iteration: 477, loss: 4.962935166771147e-13\n",
      "Iteration: 478, loss: 4.962935166771147e-13\n",
      "Iteration: 479, loss: 4.962935166771147e-13\n",
      "Iteration: 480, loss: 4.962935166771147e-13\n",
      "Iteration: 481, loss: 4.962935166771147e-13\n",
      "Iteration: 482, loss: 4.962935166771147e-13\n",
      "Iteration: 483, loss: 4.962935166771147e-13\n",
      "Iteration: 484, loss: 4.962935166771147e-13\n",
      "Iteration: 485, loss: 4.962935166771147e-13\n",
      "Iteration: 486, loss: 4.962935166771147e-13\n",
      "Iteration: 487, loss: 4.962935166771147e-13\n",
      "Iteration: 488, loss: 4.962935166771147e-13\n",
      "Iteration: 489, loss: 4.962935166771147e-13\n",
      "Iteration: 490, loss: 4.962935166771147e-13\n",
      "Iteration: 491, loss: 4.962935166771147e-13\n",
      "Iteration: 492, loss: 4.962935166771147e-13\n",
      "Iteration: 493, loss: 4.962935166771147e-13\n",
      "Iteration: 494, loss: 4.962935166771147e-13\n",
      "Iteration: 495, loss: 4.962935166771147e-13\n",
      "Iteration: 496, loss: 4.962935166771147e-13\n",
      "Iteration: 497, loss: 4.962935166771147e-13\n",
      "Iteration: 498, loss: 4.962935166771147e-13\n",
      "Iteration: 499, loss: 4.962935166771147e-13\n"
     ]
    }
   ],
   "source": [
    "mu_0 = 30/m\n",
    "rho = 0.9\n",
    "U_0 = np.random.normal(size=(n, r))\n",
    "n_iter = 500\n",
    "p_fail = 0.3\n",
    "\n",
    "model_SPL = stochastic_prox_linear(mu_0, rho, U_0, n_iter, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f1ea2097790>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1, figsize = (8, 8))\n",
    "#plt.ylim((1e-10, 0.0002))\n",
    "plt.semilogy(list(range(1, 501)), model_SPL[0], label=\"SPL, $\\\\rho = 0.95, \\\\mu_{0} = 30/m$\")\n",
    "plt.semilogy(list(range(1, 501)), model_IPL[0], label=\"IPL, $\\\\rho = 0.75, \\\\mu_{0} = 30/m$\")\n",
    "plt.ylabel(\"Loss\", fontsize=20)\n",
    "plt.xlabel(\"Iterations\", fontsize=20)\n",
    "plt.legend(fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
